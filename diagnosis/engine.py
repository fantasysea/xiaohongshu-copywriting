#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–‡æ¡ˆè¯Šæ–­å¼•æ“
Copy Diagnosis Engine

æä¾›5ç»´åº¦æ–‡æ¡ˆè´¨é‡åˆ†æ
"""

import json
import os
import re
from typing import Dict, List, Optional, Any


class CopyDiagnosis:
    """æ–‡æ¡ˆè¯Šæ–­å™¨ - 5ç»´åº¦è´¨é‡åˆ†æ"""
    
    def __init__(self, industries_dir: str, formulas_dir: str, diagnosis_dir: str):
        """
        åˆå§‹åŒ–è¯Šæ–­å™¨
        
        Args:
            industries_dir: è¡Œä¸šé…ç½®ç›®å½•
            formulas_dir: æ ‡é¢˜å…¬å¼ç›®å½•
            diagnosis_dir: è¯Šæ–­æ¨¡å—ç›®å½•
        """
        self.industries_dir = industries_dir
        self.formulas_dir = formulas_dir
        self.diagnosis_dir = diagnosis_dir
        self.sensitive_words = self._load_sensitive_words()
    
    def _load_sensitive_words(self) -> Dict:
        """åŠ è½½æ•æ„Ÿè¯åº“"""
        try:
            filepath = os.path.join(self.diagnosis_dir, 'sensitive_words.json')
            with open(filepath, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"âš ï¸  åŠ è½½æ•æ„Ÿè¯åº“å¤±è´¥: {e}")
            return {}
    
    def diagnose(self, title: str, body: str, industry_id: str) -> Dict:
        """
        5ç»´åº¦æ–‡æ¡ˆè¯Šæ–­
        
        Args:
            title: æ ‡é¢˜
            body: æ­£æ–‡
            industry_id: è¡Œä¸šID
        
        Returns:
            è¯Šæ–­æŠ¥å‘Š
        """
        full_text = title + " " + body
        
        dimensions = {
            "click_rate": self._analyze_click_rate(title, industry_id),
            "completion_rate": self._analyze_completion(body),
            "conversion": self._analyze_conversion(body),
            "compliance": self._analyze_compliance(full_text),
            "seo": self._analyze_seo(full_text, industry_id)
        }
        
        # è®¡ç®—æ€»åˆ†
        overall_score = sum(d['score'] for d in dimensions.values()) // len(dimensions)
        
        return {
            "overall_score": overall_score,
            "dimensions": dimensions,
            "improved_version": self._generate_improved_version(title, body, dimensions)
        }
    
    def _analyze_click_rate(self, title: str, industry_id: str) -> Dict:
        """ç‚¹å‡»ç‡åˆ†æ"""
        score = 70
        suggestions = []
        
        # æ£€æŸ¥æ ‡é¢˜é•¿åº¦
        if len(title) <= 20:
            score += 10
        else:
            suggestions.append("æ ‡é¢˜å»ºè®®æ§åˆ¶åœ¨20å­—ä»¥å†…ï¼Œé¿å…è¢«æˆªæ–­")
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«emoji
        if any(ord(c) > 127 for c in title):
            score += 10
        else:
            suggestions.append("å»ºè®®æ·»åŠ emojiå¢å¼ºè§†è§‰å¸å¼•åŠ›")
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ•°å­—
        if any(c.isdigit() for c in title):
            score += 5
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æƒ…ç»ªåŒ–è¯æ±‡
        emotion_words = ['ç»', 'å¿…', 'ç¥', 'yyds', 'å°ç¥', 'ç»äº†']
        if any(w in title for w in emotion_words):
            score += 5
        else:
            suggestions.append("å¯ä»¥å°è¯•åŠ å…¥æƒ…ç»ªåŒ–è¯æ±‡æå‡ç‚¹å‡»æ¬²")
        
        return {
            "score": min(score, 100),
            "analysis": f"æ ‡é¢˜é•¿åº¦{len(title)}å­—ï¼Œ{'ç¬¦åˆ' if len(title) <= 20 else 'è¶…å‡º'}æ¨èèŒƒå›´",
            "suggestions": suggestions if suggestions else ["æ ‡é¢˜å¸å¼•åŠ›è‰¯å¥½ï¼Œå¯å°è¯•A/Bæµ‹è¯•ä¸åŒç‰ˆæœ¬"]
        }
    
    def _analyze_completion(self, body: str) -> Dict:
        """å®Œè¯»ç‡åˆ†æ"""
        score = 65
        suggestions = []
        
        # æ£€æŸ¥å¼€å¤´
        if body.startswith(('å§å¦¹ä»¬', 'å®¶äººä»¬', 'å®å­ä»¬', 'å“ˆå–½')):
            score += 10
        else:
            suggestions.append("å¼€å¤´å»ºè®®ç”¨äº²åˆ‡çš„ç§°å‘¼æ‹‰è¿‘è·ç¦»")
        
        # æ£€æŸ¥æ®µè½æ•°
        paragraphs = [p for p in body.split('\n\n') if p.strip()]
        if 3 <= len(paragraphs) <= 6:
            score += 10
        elif len(paragraphs) < 3:
            suggestions.append("æ­£æ–‡å»ºè®®åˆ†3-6æ®µï¼Œå½“å‰æ®µè½æ•°åå°‘")
        else:
            suggestions.append("æ®µè½æ•°è¾ƒå¤šï¼Œå»ºè®®ç²¾ç®€å†…å®¹")
        
        # æ£€æŸ¥emojiä½¿ç”¨
        emoji_count = sum(1 for c in body if ord(c) > 127)
        if emoji_count >= 3:
            score += 10
        else:
            suggestions.append("å»ºè®®å¢åŠ emojiä½¿ç”¨ï¼Œæå‡é˜…è¯»ä½“éªŒ")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é’©å­
        hook_words = ['ç§˜å¯†', 'ç§˜è¯€', 'æŠ€å·§', 'æ–¹æ³•', 'æ”»ç•¥', 'å¿…çœ‹']
        if any(w in body for w in hook_words):
            score += 5
        else:
            suggestions.append("æ­£æ–‡å»ºè®®åŒ…å«å…·ä½“çš„æŠ€å·§æˆ–æ–¹æ³•")
        
        return {
            "score": min(score, 100),
            "analysis": f"æ­£æ–‡å…±{len(paragraphs)}æ®µï¼Œemojiä½¿ç”¨{emoji_count}ä¸ª",
            "suggestions": suggestions if suggestions else ["æ­£æ–‡ç»“æ„è‰¯å¥½ï¼Œä¿¡æ¯å¯†åº¦é€‚ä¸­"]
        }
    
    def _analyze_conversion(self, body: str) -> Dict:
        """è½¬åŒ–åŠ›åˆ†æ"""
        score = 60
        suggestions = []
        
        # æ£€æŸ¥CTA
        cta_words = ['ç‚¹èµ', 'æ”¶è—', 'å…³æ³¨', 'è¯„è®º', 'è½¬å‘', 'ç§ä¿¡']
        has_cta = any(w in body for w in cta_words)
        if has_cta:
            score += 15
        else:
            suggestions.append("ç»“å°¾æ·»åŠ æ˜ç¡®çš„è¡ŒåŠ¨å·å¬ï¼ˆç‚¹èµ/æ”¶è—/å…³æ³¨ï¼‰")
        
        # æ£€æŸ¥ä¿¡ä»»èƒŒä¹¦
        trust_words = ['äº²æµ‹', 'çœŸå®', 'å®æµ‹', 'è‡ªç”¨', 'å›è´­', 'æ¨è']
        if any(w in body for w in trust_words):
            score += 10
        else:
            suggestions.append("å¯ä»¥åŠ å…¥ä¿¡ä»»èƒŒä¹¦ï¼ˆäº²æµ‹/çœŸå®ä½“éªŒï¼‰")
        
        # æ£€æŸ¥ç¦åˆ©æ‰¿è¯º
        benefit_words = ['é€', 'ç¦åˆ©', 'å…è´¹', 'åˆ†äº«', 'æ•´ç†']
        if any(w in body for w in benefit_words):
            score += 10
        else:
            suggestions.append("å¯ä»¥åŠ å…¥ç¦åˆ©æ‰¿è¯ºæå‡è½¬åŒ–")
        
        # æ£€æŸ¥ç´§è¿«æ„Ÿ
        urgency_words = ['é™æ—¶', 'å¿«', 'èµ¶ç´§', 'é©¬ä¸Š', 'ç«‹å³']
        if any(w in body for w in urgency_words):
            score += 5
        
        return {
            "score": min(score, 100),
            "analysis": f"{'æœ‰' if has_cta else 'æ— '}æ˜ç¡®CTAï¼Œè½¬åŒ–å¼•å¯¼{'è‰¯å¥½' if score > 70 else 'éœ€åŠ å¼º'}",
            "suggestions": suggestions if suggestions else ["è½¬åŒ–å¼•å¯¼è¾ƒå¥½ï¼Œå¯æµ‹è¯•ä¸åŒCTAæ•ˆæœ"]
        }
    
    def _analyze_compliance(self, text: str) -> Dict:
        """åˆè§„æ£€æŸ¥"""
        score = 95
        warnings = []
        
        # æ£€æŸ¥æé™è¯
        extreme_words = self.sensitive_words.get('extreme_words', [])
        found_extreme = [w for w in extreme_words if w in text]
        if found_extreme:
            score -= len(found_extreme) * 10
            warnings.append(f"å‘ç°æé™è¯: {', '.join(found_extreme[:3])}")
        
        # æ£€æŸ¥åŒ»ç–—å®£ç§°
        medical_words = self.sensitive_words.get('medical_claims', [])
        found_medical = [w for w in medical_words if w in text]
        if found_medical:
            score -= len(found_medical) * 15
            warnings.append(f"å‘ç°åŒ»ç–—ç›¸å…³è¯æ±‡: {', '.join(found_medical[:3])}")
        
        # æ£€æŸ¥è™šå‡æ‰¿è¯º
        false_words = self.sensitive_words.get('false_promises', [])
        found_false = [w for w in false_words if w in text]
        if found_false:
            score -= len(found_false) * 10
            warnings.append(f"å‘ç°ç»å¯¹åŒ–ç”¨è¯­: {', '.join(found_false[:3])}")
        
        # æ£€æŸ¥å¹³å°è¿è§„
        platform_words = self.sensitive_words.get('platform_violations', [])
        found_platform = [w for w in platform_words if w in text]
        if found_platform:
            score -= len(found_platform) * 20
            warnings.append(f"å‘ç°å¹³å°è¿è§„è¯: {', '.join(found_platform[:3])}")
        
        return {
            "score": max(score, 0),
            "analysis": f"{'å‘ç°' if warnings else 'æœªå‘ç°'}æ•æ„Ÿè¯ï¼Œåˆè§„æ€§{'éœ€ä¼˜åŒ–' if warnings else 'è‰¯å¥½'}",
            "warnings": warnings if warnings else ["æœªå‘ç°æ•æ„Ÿè¯ï¼Œå¯æ”¾å¿ƒå‘å¸ƒ"],
            "suggestions": ["å»ºè®®æ›¿æ¢æ•æ„Ÿè¯ï¼Œä½¿ç”¨æ›´æ¸©å’Œçš„è¡¨è¾¾"] if warnings else []
        }
    
    def _analyze_seo(self, text: str, industry_id: str) -> Dict:
        """SEOåˆ†æ"""
        score = 70
        suggestions = []
        
        # åŠ è½½è¡Œä¸šå…³é”®è¯
        try:
            industry_file = os.path.join(self.industries_dir, f'{industry_id}.json')
            with open(industry_file, 'r', encoding='utf-8') as f:
                industry_data = json.load(f)
                industry_keywords = industry_data.get('keywords', [])
        except:
            industry_keywords = []
        
        # æ£€æŸ¥å…³é”®è¯è¦†ç›–
        if industry_keywords:
            matched = [k for k in industry_keywords if k in text]
            coverage = len(matched) / min(len(industry_keywords), 10) * 100
            score = int(coverage)
            
            if coverage < 30:
                suggestions.append(f"å…³é”®è¯è¦†ç›–ç‡{coverage:.0f}%ï¼Œå»ºè®®æ·»åŠ æ›´å¤šè¡Œä¸šå…³é”®è¯")
            
            # æ¨èæœªä½¿ç”¨çš„å…³é”®è¯
            unused = [k for k in industry_keywords[:20] if k not in text]
            if unused:
                suggestions.append(f"æ¨èæ·»åŠ å…³é”®è¯: {', '.join(unused[:5])}")
        
        # æ£€æŸ¥è¯é¢˜æ ‡ç­¾
        hashtag_pattern = r'#\w+'
        hashtags = re.findall(hashtag_pattern, text)
        if len(hashtags) >= 5:
            score += 10
        else:
            suggestions.append(f"å½“å‰è¯é¢˜æ ‡ç­¾{len(hashtags)}ä¸ªï¼Œå»ºè®®æ·»åŠ è‡³5-8ä¸ª")
        
        return {
            "score": min(score, 100),
            "analysis": f"å…³é”®è¯è¦†ç›–ç‡{score}%ï¼Œè¯é¢˜æ ‡ç­¾{len(hashtags)}ä¸ª",
            "suggestions": suggestions if suggestions else ["SEOä¼˜åŒ–è‰¯å¥½ï¼Œæœç´¢å¯è§åº¦é«˜"]
        }
    
    def _generate_improved_version(self, title: str, body: str, dimensions: Dict) -> str:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®ç‰ˆæœ¬"""
        suggestions = []
        
        for dim_name, dim_data in dimensions.items():
            if dim_data.get('suggestions'):
                suggestions.extend(dim_data['suggestions'][:2])
        
        if not suggestions:
            return "æ–‡æ¡ˆè´¨é‡è‰¯å¥½ï¼Œæš‚æ— ä¼˜åŒ–å»ºè®®"
        
        return "ä¼˜åŒ–å»ºè®®ï¼š\n" + "\n".join(f"{i+1}. {s}" for i, s in enumerate(suggestions[:5]))


# ä¾¿æ·å‡½æ•°
def diagnose_copy(title: str, body: str, industry_id: str) -> Dict:
    """
    ä¾¿æ·å‡½æ•°ï¼šè¯Šæ–­æ–‡æ¡ˆ
    
    Args:
        title: æ ‡é¢˜
        body: æ­£æ–‡
        industry_id: è¡Œä¸šID
    
    Returns:
        è¯Šæ–­æŠ¥å‘Š
    """
    base_dir = os.path.dirname(os.path.abspath(__file__))
    parent_dir = os.path.dirname(base_dir)
    
    diagnosis = CopyDiagnosis(
        industries_dir=os.path.join(parent_dir, 'industries'),
        formulas_dir=os.path.join(parent_dir, 'formulas'),
        diagnosis_dir=base_dir
    )
    
    return diagnosis.diagnose(title, body, industry_id)


if __name__ == '__main__':
    # æµ‹è¯•
    print("ğŸ” æ–‡æ¡ˆè¯Šæ–­æµ‹è¯•")
    print("-" * 50)
    
    test_title = "3æ”¯é»„çš®ç´ é¢œå£çº¢ï¼æ˜¾ç™½ä¸æŒ‘çš®"
    test_body = """å§å¦¹ä»¬ï¼Œä»Šå¤©åˆ†äº«3æ”¯æˆ‘ç§è—çš„ç´ é¢œç¥å™¨

ğŸ’„ç¬¬ä¸€æ”¯ï¼šè¶…æ˜¾ç™½
è¿™æ”¯çœŸçš„ç»äº†ï¼é»„çš®æ¶‚ä¸Šå»ç›´æ¥ç™½ä¸€ä¸ªåº¦

ğŸ’„ç¬¬äºŒæ”¯ï¼šè¶…æ»‹æ¶¦
è¿™æ”¯æ˜¯æˆ‘çš„å¿ƒå¤´å¥½ï¼Œæ—¥å¸¸é€šå‹¤å¿…å¤‡

ğŸ’„ç¬¬ä¸‰æ”¯ï¼šè¶…æŒä¹…
è¿™æ”¯æ˜¯æœ€è¿‘çš„å®è—å‘ç°ï¼Œæ€§ä»·æ¯”è¶…é«˜

âœ¨è§‰å¾—æœ‰ç”¨çš„è¯è®°å¾—ç‚¹èµæ”¶è—å“¦ï¼

#ç¾å¦†åˆ†äº« #å£çº¢è¯•è‰² #é»„çš®æ˜¾ç™½"""
    
    result = diagnose_copy(test_title, test_body, "beauty")
    
    print(f"\næ€»è¯„åˆ†: {result['overall_score']}/100\n")
    print("å„ç»´åº¦è¯„åˆ†:")
    for dim_name, dim_data in result['dimensions'].items():
        print(f"  {dim_name}: {dim_data['score']}/100")
    print(f"\nä¼˜åŒ–å»ºè®®:\n{result['improved_version']}")
